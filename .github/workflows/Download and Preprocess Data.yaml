name: Download Dataset from Kaggle

on:
  push:
    branches:
      - main

jobs:
  download-dataset:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v3
        with:
          # Use Git LFS to download large files
          submodules: 'recursive'
          fetch-depth: 0
          lfs: true
      - name: Install Kaggle API
        run: pip install kaggle
      - name: Download dataset from Kaggle
        env:
          KAGGLE_USERNAME: ${{ secrets.KAGGLE_N }}
          KAGGLE_KEY: ${{ secrets.KAGGLE_K }}
        run: |
          mkdir -p data
          kaggle datasets download -d clmentbisaillon/fake-and-real-news-dataset -p data/
          echo "dataset_downloaded=true" >> $GITHUB_ENV
      - name: Unzip dataset
        run: unzip -q data/*.zip -d data/
      - name: Commit and Push changes - 1
        uses: EndBug/add-and-commit@v9
        with:
          message: 'Added data'
          add: 'data/*'
      - name: Install Git LFS
        run: |
          curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | sudo bash
          sudo apt-get install git-lfs
        shell: bash
      - name: Install Python
        uses: actions/setup-python@v3
        with:
          python-version: 3.9
      - name: Upgrade pip
        run: pip install --upgrade pip
      - name: Install dependencies
        run: pip install -r req_new.txt
      - name: Process data
        run: |
          python preprocess.py
          # Save the processed data using Git LFS
          git lfs track "data/cleaned_data.csv"
      - name: Commit and Push changes - 2
        run: |
          git add data/cleaned_data.csv
          git commit -m "Added processed data"
          git push
        env:
          GITHUB_TOKEN: ${{ secrets.SECRET }}
